{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, LeakyReLU, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from self_train import SelfPlayIteration\n",
    "from config import BOARD_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from random import shuffle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from config import BOARD_SIZE, GameState, WHITE, BLACK\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy, copy\n",
    "from random import choice\n",
    "\n",
    "from MCTS import MCTS\n",
    "#from board import Board\n",
    "from config import GameState, WHITE, BLACK, BOARD_SIZE\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "PATH_TO_DATA = './../self_play_models/'\n",
    "PATH_TO_MODELS = PATH_TO_DATA + '{}.h5'\n",
    "PATH_TO_HISTORY = PATH_TO_DATA + 'history/{}.h5'\n",
    "GENERATING_DATA_MCTS_DEPTH = 10\n",
    "DATASET_SIZE = 25\n",
    "COMPETING_MCTS_DEPTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_nn(name):\n",
    "    print('model ', name, ' was loaded from file ', PATH_TO_MODELS.format(name))\n",
    "    model = load_model(PATH_TO_MODELS.format(name))\n",
    "    return model\n",
    "\n",
    "\n",
    "def _save_old_model(model):\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        if os.path.isfile(PATH_TO_HISTORY.format(str(cnt))):\n",
    "            cnt += 1\n",
    "            continue\n",
    "        model.save(PATH_TO_HISTORY.format(str(cnt)))\n",
    "        return\n",
    "\n",
    "\n",
    "class SelfPlayIteration(object):\n",
    "    def __init__(self):\n",
    "        self._main_player_nn = _load_nn('main_player')\n",
    "        self._opponent_nn = _load_nn('main_player')\n",
    "        self._mcts = MCTS(self._main_player_nn, GENERATING_DATA_MCTS_DEPTH)\n",
    "\n",
    "    def iterate(self):\n",
    "        train_data = self._create_self_play_dataset(DATASET_SIZE)\n",
    "        print('-------------------TRAINING STAGE-------------------\\ndata size {}'.format(str(len(train_data))))\n",
    "        for _ in range(5):\n",
    "            self._main_player_nn.fit_generator(\n",
    "                self._train_generator(train_data), epochs=1, verbose=1,\n",
    "                steps_per_epoch=len(train_data) // BATCH_SIZE, shuffle=True\n",
    "            )\n",
    "        # TODO(check if main_player is better than opponent)\n",
    "        print('-------------------COMPETING STAGE------------------')\n",
    "        if (self._compete()):\n",
    "            print('Great training! Updating main model.')\n",
    "            self._main_player_nn.save(PATH_TO_MODELS.format('main_player'))\n",
    "            _save_old_model(self._opponent_nn)\n",
    "            return\n",
    "        print('Oh... Old model is better. Keeping the old one. Try again.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _train_generator(data):\n",
    "        size, X, y, win = 0, [], [], []\n",
    "        for item in data:\n",
    "            X.append(item[0])\n",
    "            y.append(item[1])\n",
    "            win.append(item[2])\n",
    "            size += 1\n",
    "            if size == BATCH_SIZE:\n",
    "                yield np.float64(np.array(X)).reshape((size, 15, 15)), \\\n",
    "                      [np.array(y).reshape((size, 225)), np.array(win).reshape((size, 1))]\n",
    "                size, X, y, win = 0, [], [], []\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_symmetries(board, label):\n",
    "        label = np.array(label).reshape((15, 15))\n",
    "        syms = list()\n",
    "        syms.append((\n",
    "            deepcopy(board.get_board().tolist()),\n",
    "            deepcopy(label.ravel().tolist()),\n",
    "        ))\n",
    "        syms.append((\n",
    "            deepcopy(np.rot90(board.get_board()).tolist()),\n",
    "            deepcopy(np.rot90(label).ravel().tolist()),\n",
    "        ))\n",
    "        syms.append((\n",
    "            deepcopy(np.rot90(board.get_board(), 2).tolist()),\n",
    "            deepcopy(np.rot90(label, 2).ravel().tolist()),\n",
    "        ))\n",
    "        syms.append((\n",
    "            deepcopy(np.rot90(board.get_board(), 3).tolist()),\n",
    "            deepcopy(np.rot90(label, 3).ravel().tolist()),\n",
    "        ))\n",
    "        return syms\n",
    "\n",
    "    def _play_game(self, first_move=None):\n",
    "        print('-----------------PLAY-GAME-----------------')\n",
    "        game_dataset = []\n",
    "        board = Board()\n",
    "        player = BLACK\n",
    "        is_winner_from_black_perspective = 1\n",
    "        if first_move is not None:\n",
    "            board.execute_move((first_move[0], first_move[1]), player)\n",
    "            player = -player\n",
    "            is_winner_from_black_perspective = -is_winner_from_black_perspective\n",
    "        while board.get_state() == GameState.InProgress:\n",
    "            #print('g', end='')\n",
    "            label_probs = self._mcts.get_new_actions_probs(board)\n",
    "            # TODO (here we push colors as a third train param then don't forget to change it to is_win!)\n",
    "            syms = SelfPlayIteration._generate_symmetries(board, label_probs)\n",
    "            for s in syms:\n",
    "                game_dataset.append(np.array(\n",
    "                    [s[0], s[1], [np.float64(is_winner_from_black_perspective)]]\n",
    "                ))\n",
    "            action = np.random.choice(len(label_probs), p=label_probs)\n",
    "            #print('({}, {}), '.format(action // 15, action % 15), end='')\n",
    "            board.execute_move((action // BOARD_SIZE, action % BOARD_SIZE), player)\n",
    "            player = -player\n",
    "            is_winner_from_black_perspective = -is_winner_from_black_perspective\n",
    "        if board.get_state() == GameState.Black:\n",
    "            # BLACK is winner -> third param ok\n",
    "            return game_dataset\n",
    "        if board.get_state() == GameState.White:\n",
    "            for i in range(len(game_dataset)):\n",
    "                # reverse is_winner label\n",
    "                game_dataset[i][2][0] = - game_dataset[i][2][0]\n",
    "            return game_dataset\n",
    "        if board.get_state() == GameState.Draw:\n",
    "            for i in range(len(game_dataset)):\n",
    "                game_dataset[i][2][0] = np.float64(0)\n",
    "            return game_dataset\n",
    "        raise ValueError('unsupported state')\n",
    "\n",
    "    def _create_self_play_dataset(self, size=25):\n",
    "        print('-----------------CREATING-DATASET-----------------')\n",
    "        dataset = []\n",
    "        for _ in range(size):\n",
    "            dataset.extend(self._play_game())\n",
    "        for _ in range(25):\n",
    "            i = random.randint(0,225)\n",
    "            dataset.extend(self._play_game((i // BOARD_SIZE, i % BOARD_SIZE)))\n",
    "        shuffle(dataset)\n",
    "        return dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def _compete_single_game(black_player, white_player):\n",
    "        print('-', end='')\n",
    "        board = Board()\n",
    "        players = [black_player, white_player]\n",
    "        colors = [BLACK, WHITE]\n",
    "        cur_ind = 0\n",
    "        while board.get_state() == GameState.InProgress:\n",
    "            action = players[cur_ind](board)\n",
    "            board.execute_move((action // BOARD_SIZE, action % BOARD_SIZE), colors[cur_ind])\n",
    "            cur_ind = (cur_ind + 1) % 2\n",
    "        return board.get_state()\n",
    "\n",
    "    def _compete(self, games_cnt=20):\n",
    "        print('--------------------COMPETING------------------')\n",
    "        main_player_won_cnt = 0\n",
    "        opponent_won_cnt = 0\n",
    "        draws = 0\n",
    "\n",
    "        main_player_mcts = MCTS(self._main_player_nn, COMPETING_MCTS_DEPTH)\n",
    "        opponent_mcts = MCTS(self._opponent_nn, COMPETING_MCTS_DEPTH)\n",
    "        # 1 stage: main_player - BLACK, opponent - WHITE\n",
    "        for _ in range(games_cnt):\n",
    "            result = SelfPlayIteration._compete_single_game(\n",
    "                lambda x: np.argmax(main_player_mcts.get_new_actions_probs(x, False)),\n",
    "                lambda y: np.argmax(opponent_mcts.get_new_actions_probs(y, False))\n",
    "            )\n",
    "            if result == GameState.Black:\n",
    "                main_player_won_cnt += 1\n",
    "            elif result == GameState.White:\n",
    "                opponent_won_cnt += 1\n",
    "\n",
    "        # 2 stage: main_player - WHIRE, opponent - BLACK\n",
    "        for _ in range(games_cnt):\n",
    "            result = SelfPlayIteration._compete_single_game(\n",
    "                lambda x: np.argmax(opponent_mcts.get_new_actions_probs(x, False)),\n",
    "                lambda y: np.argmax(main_player_mcts.get_new_actions_probs(y, False))\n",
    "            )\n",
    "            if result == GameState.Black:\n",
    "                opponent_won_cnt += 1\n",
    "            elif result == GameState.White:\n",
    "                main_player_won_cnt += 1\n",
    "\n",
    "        if main_player_won_cnt + opponent_won_cnt != 0:\n",
    "            if main_player_won_cnt / (main_player_won_cnt + opponent_won_cnt) >= 0.6:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    self_play = SelfPlayIteration()\n",
    "    self_play.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
