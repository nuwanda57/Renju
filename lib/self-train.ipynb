{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, LeakyReLU, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from config import BOARD_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from random import shuffle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from config import BOARD_SIZE, GameState, WHITE, BLACK\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy, copy\n",
    "from random import choice\n",
    "\n",
    "from MCTS import MCTS\n",
    "from config import GameState, WHITE, BLACK, BOARD_SIZE\n",
    "from board import Board\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "PATH_TO_DATA = './../self_train_models/'\n",
    "PATH_TO_MODELS = PATH_TO_DATA + '{}.h5'\n",
    "PATH_TO_HISTORY = PATH_TO_DATA + 'history/{}.h5'\n",
    "GENERATING_DATA_MCTS_DEPTH = 20\n",
    "DATASET_SIZE = 75\n",
    "COMPETING_MCTS_DEPTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_nn(name):\n",
    "    print('model ', name, ' was loaded from file ', PATH_TO_MODELS.format(name))\n",
    "    model = load_model(PATH_TO_MODELS.format(name))\n",
    "    return model\n",
    "\n",
    "\n",
    "def _save_old_model(model):\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        if os.path.isfile(PATH_TO_HISTORY.format(str(cnt))):\n",
    "            cnt += 1\n",
    "            continue\n",
    "        model.save(PATH_TO_HISTORY.format(str(cnt)))\n",
    "        return\n",
    "\n",
    "\n",
    "class SelfPlayIteration(object):\n",
    "    def __init__(self):\n",
    "        self._main_player_nn = _load_nn('main_player')\n",
    "        self._opponent_nn = _load_nn('main_player')\n",
    "        self._mcts = MCTS(self._main_player_nn, GENERATING_DATA_MCTS_DEPTH)\n",
    "\n",
    "    def iterate(self):\n",
    "        train_data = self._create_self_train_dataset(DATASET_SIZE)\n",
    "        print('-------------------TRAINING STAGE-------------------\\ndata size {}'.format(str(len(train_data))))\n",
    "        for _ in range(5):\n",
    "            self._main_player_nn.fit_generator(\n",
    "                self._train_generator(train_data), epochs=1, verbose=1,\n",
    "                steps_per_epoch=len(train_data) // BATCH_SIZE, shuffle=True\n",
    "            )\n",
    "        # TODO(check if main_player is better than opponent)\n",
    "        print('-------------------COMPETING STAGE------------------')\n",
    "        if (self._compete()):\n",
    "            print('Great training! Updating main model.')\n",
    "            self._main_player_nn.save(PATH_TO_MODELS.format('main_player'))\n",
    "            _save_old_model(self._opponent_nn)\n",
    "            return\n",
    "        print('Oh... Old model is better. Keeping the old one. Try again.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _train_generator(data):\n",
    "        size, X, y, win = 0, [], [], []\n",
    "        for item in data:\n",
    "            X.append(item[0])\n",
    "            y.append(item[1])\n",
    "            win.append(item[2])\n",
    "            size += 1\n",
    "            if size == BATCH_SIZE:\n",
    "                yield np.float64(np.array(X)).reshape((size, 15, 15)), \\\n",
    "                      [np.array(y).reshape((size, 225)), np.array(win).reshape((size, 1))]\n",
    "                size, X, y, win = 0, [], [], []\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_symmetries(board, label):\n",
    "        label = np.array(label).reshape((15, 15))\n",
    "        syms = list()\n",
    "        syms.append((\n",
    "            deepcopy(board.get_board().tolist()),\n",
    "            deepcopy(label.ravel().tolist()),\n",
    "        ))\n",
    "        syms.append((\n",
    "            deepcopy(np.rot90(board.get_board()).tolist()),\n",
    "            deepcopy(np.rot90(label).ravel().tolist()),\n",
    "        ))\n",
    "        syms.append((\n",
    "            deepcopy(np.rot90(board.get_board(), 2).tolist()),\n",
    "            deepcopy(np.rot90(label, 2).ravel().tolist()),\n",
    "        ))\n",
    "        syms.append((\n",
    "            deepcopy(np.rot90(board.get_board(), 3).tolist()),\n",
    "            deepcopy(np.rot90(label, 3).ravel().tolist()),\n",
    "        ))\n",
    "        return syms\n",
    "\n",
    "    def _play_game(self, first_move=None):\n",
    "        print('-', end='')\n",
    "        game_dataset = []\n",
    "        board = Board()\n",
    "        player = BLACK\n",
    "        is_winner_from_black_perspective = 1\n",
    "        if first_move is not None:\n",
    "            board.execute_move((first_move[0], first_move[1]), player)\n",
    "            player = -player\n",
    "            is_winner_from_black_perspective = -is_winner_from_black_perspective\n",
    "        moves_cnt = 0\n",
    "        while board.get_state() == GameState.InProgress:\n",
    "            moves_cnt += 1\n",
    "            #print('g', end='')\n",
    "            label_probs = self._mcts.get_new_actions_probs(board)\n",
    "            # TODO (here we push colors as a third train param then don't forget to change it to is_win!)\n",
    "            syms = SelfPlayIteration._generate_symmetries(board, label_probs)\n",
    "            for s in syms:\n",
    "                game_dataset.append(np.array(\n",
    "                    [s[0], s[1], [np.float64(is_winner_from_black_perspective)]]\n",
    "                ))\n",
    "            action = np.random.choice(len(label_probs), p=label_probs)\n",
    "            #print('({}, {}), '.format(action // 15, action % 15), end='')\n",
    "            board.execute_move((action // BOARD_SIZE, action % BOARD_SIZE), player)\n",
    "            player = -player\n",
    "            is_winner_from_black_perspective = -is_winner_from_black_perspective\n",
    "        print(moves_cnt, end='')\n",
    "        if board.get_state() == GameState.Black:\n",
    "            # BLACK is winner -> third param ok\n",
    "            return game_dataset\n",
    "        if board.get_state() == GameState.White:\n",
    "            for i in range(len(game_dataset)):\n",
    "                # reverse is_winner label\n",
    "                game_dataset[i][2][0] = - game_dataset[i][2][0]\n",
    "            return game_dataset\n",
    "        if board.get_state() == GameState.Draw:\n",
    "            for i in range(len(game_dataset)):\n",
    "                game_dataset[i][2][0] = np.float64(0)\n",
    "            return game_dataset\n",
    "        raise ValueError('unsupported state')\n",
    "\n",
    "    def _create_self_train_dataset(self, size=DATASET_SIZE):\n",
    "        print('-----------------CREATING-DATASET-----------------')\n",
    "        dataset = []\n",
    "        for _ in range(size):\n",
    "            dataset.extend(self._play_game())\n",
    "        for _ in range(25):\n",
    "            i = random.randint(0,225)\n",
    "            dataset.extend(self._play_game((i // BOARD_SIZE, i % BOARD_SIZE)))\n",
    "        shuffle(dataset)\n",
    "        return dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def _compete_single_game(black_player, white_player):\n",
    "        print('-', end='')\n",
    "        board = Board()\n",
    "        players = [black_player, white_player]\n",
    "        colors = [BLACK, WHITE]\n",
    "        cur_ind = 0\n",
    "        while board.get_state() == GameState.InProgress:\n",
    "            action = players[cur_ind](board)\n",
    "            board.execute_move((action // BOARD_SIZE, action % BOARD_SIZE), colors[cur_ind])\n",
    "            cur_ind = (cur_ind + 1) % 2\n",
    "        return board.get_state()\n",
    "\n",
    "    def _compete(self, games_cnt=30):\n",
    "        print('--------------------COMPETING------------------')\n",
    "        main_player_won_cnt = 0\n",
    "        opponent_won_cnt = 0\n",
    "        draws = 0\n",
    "\n",
    "        main_player_mcts = MCTS(self._main_player_nn, COMPETING_MCTS_DEPTH)\n",
    "        opponent_mcts = MCTS(self._opponent_nn, COMPETING_MCTS_DEPTH)\n",
    "        # 1 stage: main_player - BLACK, opponent - WHITE\n",
    "        for _ in range(games_cnt):\n",
    "            result = SelfPlayIteration._compete_single_game(\n",
    "                lambda x: np.argmax(main_player_mcts.get_new_actions_probs(x, False)),\n",
    "                lambda y: np.argmax(opponent_mcts.get_new_actions_probs(y, False))\n",
    "            )\n",
    "            if result == GameState.Black:\n",
    "                main_player_won_cnt += 1\n",
    "            elif result == GameState.White:\n",
    "                opponent_won_cnt += 1\n",
    "\n",
    "        # 2 stage: main_player - WHIRE, opponent - BLACK\n",
    "        for _ in range(games_cnt):\n",
    "            result = SelfPlayIteration._compete_single_game(\n",
    "                lambda x: np.argmax(opponent_mcts.get_new_actions_probs(x, False)),\n",
    "                lambda y: np.argmax(main_player_mcts.get_new_actions_probs(y, False))\n",
    "            )\n",
    "            if result == GameState.Black:\n",
    "                opponent_won_cnt += 1\n",
    "            elif result == GameState.White:\n",
    "                main_player_won_cnt += 1\n",
    "\n",
    "        print('main player won: {}, opponent won: {}'.format(main_player_won_cnt, opponent_won_cnt))\n",
    "        if main_player_won_cnt + opponent_won_cnt != 0:\n",
    "            if main_player_won_cnt / (main_player_won_cnt + opponent_won_cnt) >= 0.6:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  main_player  was loaded from file  ./../self_train_models/main_player.h5\n",
      "model  main_player  was loaded from file  ./../self_train_models/main_player.h5\n",
      "-----------------CREATING-DATASET-----------------\n",
      "-20-12-15-138-32-"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b004ef38b183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mself_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelfPlayIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mself_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-2f6f49e90f0e>\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_self_train_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------------TRAINING STAGE-------------------\\ndata size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-2f6f49e90f0e>\u001b[0m in \u001b[0;36m_create_self_train_dataset\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_play_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m225\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-2f6f49e90f0e>\u001b[0m in \u001b[0;36m_play_game\u001b[0;34m(self, first_move)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mmoves_cnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m#print('g', end='')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mlabel_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_new_actions_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;31m# TODO (here we push colors as a third train param then don't forget to change it to is_win!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0msyms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelfPlayIteration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_symmetries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Private/Renju/lib/MCTS.py\u001b[0m in \u001b[0;36mget_new_actions_probs\u001b[0;34m(self, board, choose_one_action, his_move, cheat, caution)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simulations_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Private/Renju/lib/MCTS.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, board)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mnext_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_player\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_board\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action_rewards\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Private/Renju/lib/MCTS.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, board)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mnext_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_player\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_board\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_action_rewards\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Private/Renju/lib/MCTS.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, board)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     )\n\u001b[1;32m    136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mcur_ucb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn_policies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visit_state_cnt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mEPS\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# not visited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcur_ucb\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcur_best_ucb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mcur_best_ucb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_ucb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    self_train = SelfPlayIteration()\n",
    "    self_train.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
